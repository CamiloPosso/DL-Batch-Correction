{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import random\n",
    "import numpy\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "\n",
    "\n",
    "from transformer_batch_corrections import Correction_data\n",
    "from asses_batch_effect import batchless_entropy_estimate, abs_effect_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA   = 'data/peptide_crosstab_1.txt'\n",
    "CrossTab = pd.read_csv(PATH_TO_DATA,   delimiter = '\\t')\n",
    "batch_size = 10\n",
    "n_batches = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3755, 6194, 2590, 6035, 924, 6433, 5947, 4613, 5408, 5183]\n",
      "[1423, 6554, 3229, 4893, 3007, 2793, 1354, 519, 3294, 6208]\n",
      "[5764, 4564, 6763, 5328, 4355, 2233, 5848, 4398, 6398, 4601]\n",
      "[2677, 6454, 5044, 3911, 5881, 5458, 1418, 51, 4926, 4047]\n",
      "[4516, 462, 5191, 3736, 2573, 6199, 4934, 5017, 1805, 2900]\n",
      "[3527, 4300, 6382, 5024, 6152, 717, 1925, 5832, 2550, 6766]\n",
      "[3702, 2172, 3174, 510, 3305, 6434, 5085, 5547, 2046, 2053]\n",
      "[3534, 2287, 4787, 13, 1641, 3098, 909, 112, 6125, 5453]\n",
      "[4809, 5673, 1704, 4403, 5357, 1406, 763, 5492, 3756, 5445]\n",
      "[2618, 1093, 4958, 6063, 4547, 5802, 5848, 5082, 6398, 5259]\n",
      "[5969, 5665, 2941, 1302, 2280, 3356, 816, 4006, 3961, 4239]\n",
      "[6942, 2835, 363, 3588, 1924, 2459, 3457, 1406, 2131, 3163]\n",
      "[283, 3433, 969, 1620, 2882, 5843, 3006, 704, 5001, 4218]\n",
      "[5321, 744, 1832, 3691, 6972, 439, 5333, 5815, 1458, 6817]\n",
      "[4711, 2767, 6563, 6858, 2691, 3229, 3799, 5695, 1947, 3568]\n",
      "[5157, 6751, 5762, 4655, 1300, 1233, 6475, 4096, 5923, 6510]\n",
      "[2917, 1355, 3896, 2274, 4228, 1106, 6886, 3798, 5747, 2466]\n",
      "[973, 2095, 2852, 2022, 4082, 1042, 6546, 6868, 6559, 903]\n",
      "[623, 4285, 803, 289, 4478, 4383, 2648, 758, 2103, 3765]\n",
      "[4212, 5881, 6599, 1911, 5679, 5727, 408, 1712, 3898, 2253]\n"
     ]
    }
   ],
   "source": [
    "test = Correction_data(CrossTab = CrossTab, depth = 1, reg_factor = 0.001, \n",
    "                       n_batches = 6, batch_size = 10, test_size = 7000, \n",
    "                       minibatch_size = 200, random_state = 107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 report : testing loss is 3.126879384051146 while full loss is 3.085192904471363 and absolute effect in testing data is 3.3266813407882183\n",
      "\n",
      "[2304, 37367, 72503, 72298, 69838, 60117, 11631, 28422, 43355, 36746]\n",
      "Training loss is 1.289315272525646\n",
      "Epoch 1 report : testing loss is 0.09131797959246966 while full loss is 0.12289504143966769 and absolute effect in testing data is 0.6241062030168641\n",
      "\n",
      "[39211, 20916, 45855, 53337, 27680, 56945, 65669, 24247, 35325, 15248]\n",
      "Training loss is 0.07508611867276646\n",
      "Epoch 2 report : testing loss is 0.0827898402215923 while full loss is 0.10227242956381222 and absolute effect in testing data is 0.5795694122056446\n",
      "\n",
      "[2681, 17962, 41640, 19055, 16688, 36088, 51262, 13297, 54197, 40098]\n",
      "Training loss is 0.07472731338341214\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\poss982\\Documents\\GitHub\\DL-Batch-Correction\\entropy_correction\\testing.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/poss982/Documents/GitHub/DL-Batch-Correction/entropy_correction/testing.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test\u001b[39m.\u001b[39;49mtrain_model(epochs \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m, report_frequency \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, abs_effect_cutoff \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m, robust_cutoff \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m, minibatch_bias \u001b[39m=\u001b[39;49m \u001b[39m0.65\u001b[39;49m, run_name \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mfry_2\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\poss982\\Documents\\GitHub\\DL-Batch-Correction\\entropy_correction\\transformer_batch_corrections.py:391\u001b[0m, in \u001b[0;36mCorrection_data.train_model\u001b[1;34m(self, epochs, abs_effect_cutoff, robust_cutoff, minibatch_bias, report_frequency, run_name)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[39mfor\u001b[39;00m _, _, y, mask \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader:\n\u001b[0;32m    390\u001b[0m     y, z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_correction(y, mask)\n\u001b[1;32m--> 391\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobjective(y, z)\n\u001b[0;32m    392\u001b[0m     full_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(loss)\n\u001b[0;32m    393\u001b[0m     data_corrected\u001b[39m.\u001b[39mappend(y\u001b[39m-\u001b[39mz)\n",
      "File \u001b[1;32mc:\\Users\\poss982\\Documents\\GitHub\\DL-Batch-Correction\\entropy_correction\\transformer_batch_corrections.py:315\u001b[0m, in \u001b[0;36mCorrection_data.objective\u001b[1;34m(self, y, z)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobjective\u001b[39m(\u001b[39mself\u001b[39m, y, z):\n\u001b[0;32m    310\u001b[0m     batch_dist \u001b[39m=\u001b[39m fisher_kldiv(y\u001b[39m-\u001b[39mz, \n\u001b[0;32m    311\u001b[0m                               \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_batches, \n\u001b[0;32m    312\u001b[0m                               \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size, \n\u001b[0;32m    313\u001b[0m                               \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatchless_entropy)\n\u001b[1;32m--> 315\u001b[0m     reg_dist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreg_factor \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39msum(z\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m    316\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mabs(batch_dist) \u001b[39m+\u001b[39m reg_dist\n",
      "File \u001b[1;32mc:\\Users\\poss982\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:32\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[39mif\u001b[39;00m has_torch_function(args):\n\u001b[0;32m     31\u001b[0m         \u001b[39mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 32\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     33\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test.train_model(epochs = 100, report_frequency = 1, abs_effect_cutoff = 0, robust_cutoff = 0, minibatch_bias = 0.65, run_name = \"fry_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Correction_data(CrossTab = CrossTab, depth = 1, reg_factor = 0.3, \n",
    "                       n_batches = 6, batch_size = 10, test_size = 7000, \n",
    "                       minibatch_size = 500, random_state = 107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.train_model(epochs = 301, report_frequency = 5, abs_effect_cutoff = 0.5, robust_cutoff = 0, minibatch_bias = 0.65, run_name = \"robust_metric_bias_shuffle_0.65_minbatch_500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Correction_data(CrossTab = CrossTab, depth = 1, reg_factor = 0.3, \n",
    "                       n_batches = 6, batch_size = 10, test_size = 7000, \n",
    "                       minibatch_size = 350, random_state = 107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.train_model(epochs = 301, report_frequency = 5, abs_effect_cutoff = 0.5, robust_cutoff = 0, minibatch_bias = 0.65, run_name = \"robust_metric_bias_shuffle_0.65_minbatch_350\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Correction_data(CrossTab = CrossTab, depth = 1, reg_factor = 0.3, \n",
    "                       n_batches = 6, batch_size = 10, test_size = 7000, \n",
    "                       minibatch_size = 100, random_state = 107)\n",
    "test.train_model(epochs = 301, report_frequency = 5, abs_effect_cutoff = 0.5, robust_cutoff = 0, minibatch_bias = 0.65, run_name = \"robust_metric_bias_shuffle_0.65_minbatch_100\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "640db03823d881b8a8fc569947ee30f9c13a0b41ec0c9dfec6424996e26d1a73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
